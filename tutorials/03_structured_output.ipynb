{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"../assets/images/hackathon.png\" alt=\"Holistic AI Hackathon Logo\" width=\"600\"/>\n",
    "</div>\n",
    "\n",
    "**Event**: [hackathon.holisticai.com](https://hackathon.holisticai.com)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Tutorial 3: Structured Output with Pydantic\n",
    "\n",
    "**Learn to get JSON responses from your agents**\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **Define schemas** with Pydantic\n",
    "2. **Create agents** that return validated JSON\n",
    "3. **Compare** natural text vs structured output\n",
    "4. **Best practices** for using structured output\n",
    "\n",
    "## Why Structured Output?\n",
    "\n",
    "- **Type safety** - Validated fields\n",
    "- **Easy parsing** - Direct JSON objects\n",
    "- **API ready** - Perfect for integrations\n",
    "- **Reliable** - No parsing errors\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Basic Python knowledge\n",
    "- Recommended: Completed `01_basic_agent.ipynb` and `02_custom_tools.ipynb`\n",
    "- Time: ~15 minutes\n",
    "\n",
    "**Note:** This tutorial is completely self-contained and uses only official packages!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-why-need",
   "metadata": {},
   "source": [
    "## Why We Need Structured Output\n",
    "\n",
    "### The Problem with Natural Text Responses\n",
    "\n",
    "When you ask an LLM a question, it naturally returns text. But in real applications, you often need:\n",
    "\n",
    "```python\n",
    "# What you get from the LLM:\n",
    "\"The temperature is 72 degrees Fahrenheit, humidity is around 65%, and it's partly cloudy.\"\n",
    "\n",
    "# What your application needs:\n",
    "{\n",
    "  \"temperature\": 72,\n",
    "  \"temperature_unit\": \"F\",\n",
    "  \"humidity\": 65,\n",
    "  \"conditions\": \"partly cloudy\"\n",
    "}\n",
    "```\n",
    "\n",
    "### Real-World Problems Without Structured Output\n",
    "\n",
    "**Problem 1: Parsing Failures**\n",
    "```python\n",
    "# LLM might say any of these:\n",
    "\"The temperature is 72Â°F\"\n",
    "\"It's 72 degrees\"\n",
    "\"About seventy-two Fahrenheit\"\n",
    "\"72F\"\n",
    "\n",
    "# Your regex will break on most of these!\n",
    "```\n",
    "\n",
    "**Problem 2: Missing or Extra Fields**\n",
    "```python\n",
    "# You expect: {\"name\": \"...\", \"age\": ..., \"email\": \"...\"}\n",
    "# LLM returns: {\"name\": \"John\", \"age\": 30}  # Missing email!\n",
    "# Or: {\"name\": \"John\", \"age\": 30, \"email\": \"...\", \"phone\": \"...\"}  # Extra field!\n",
    "```\n",
    "\n",
    "**Problem 3: Type Mismatches**\n",
    "```python\n",
    "# You expect: {\"score\": 85.5}\n",
    "# LLM returns: {\"score\": \"85.5\"}  # String instead of float!\n",
    "# Or: {\"score\": \"Eighty-five point five\"}  # Text instead of number!\n",
    "```\n",
    "\n",
    "**Problem 4: Inconsistent Format**\n",
    "```python\n",
    "# Request 1: {\"date\": \"2024-01-15\"}\n",
    "# Request 2: {\"date\": \"January 15, 2024\"}\n",
    "# Request 3: {\"date\": \"15/01/2024\"}\n",
    "# All different formats for the same thing!\n",
    "```\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "In production systems, you need:\n",
    "- **Reliability** - Code shouldn't break because of formatting changes\n",
    "- **Type Safety** - Variables must have predictable types\n",
    "- **Validation** - Data must meet business rules (e.g., age > 0)\n",
    "- **API Integration** - External systems expect exact schemas\n",
    "- **Database Storage** - Tables need consistent column types\n",
    "\n",
    "**Bottom Line:** Natural text is great for humans, but applications need structured data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-how-it-works",
   "metadata": {},
   "source": "import os\nfrom pathlib import Path\nfrom dotenv import load_dotenv\n\n# Load from .env file in parent directory\nenv_path = Path('../.env')\nif env_path.exists():\n    load_dotenv(env_path)\n    print(\"ðŸ“„ Loaded configuration from .env file\")\nelse:\n    print(\"âš ï¸  No .env file found - using environment variables\")\n\n# Verify API keys\nprint(\"\\nðŸ”‘ API Key Status:\")\nif os.getenv('HOLISTIC_AI_TEAM_ID') and os.getenv('HOLISTIC_AI_API_TOKEN'):\n    print(\"  âœ… Holistic AI Bedrock credentials loaded\")\nelif os.getenv('OPENAI_API_KEY'):\n    print(\"  âš ï¸  OpenAI API key loaded\")\nelse:\n    print(\"  âš ï¸  No API keys found\")\n\nprint(\"\\nðŸ“ Working directory:\", Path.cwd())\n\n# Import Holistic AI Bedrock helper\nimport sys\ntry:\n    sys.path.insert(0, '../core')\n    from react_agent.holistic_ai_bedrock import get_chat_model\n    print(\"\\nâœ… Holistic AI Bedrock helper loaded\")\nexcept ImportError:\n    print(\"\\nâš ï¸  Could not import from core - will use OpenAI only\")\n\n# Import official packages\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nprint(\"\\nâœ… All imports successful!\")\n"
  },
  {
   "cell_type": "markdown",
   "id": "cell-comparison",
   "metadata": {},
   "source": [
    "### JSON Mode vs Structured Outputs (Comparison)\n",
    "\n",
    "| Feature | JSON Mode | Structured Outputs |\n",
    "|---------|-----------|-------------------|\n",
    "| **Valid JSON Syntax** | - Yes | - Yes |\n",
    "| **Schema Compliance** | - No guarantee | - 100% guaranteed |\n",
    "| **Field Names** | - Might be wrong | - Exact match |\n",
    "| **Field Types** | - Might be wrong | - Type-safe |\n",
    "| **Validation** | - Manual required | - Automatic |\n",
    "| **Speed** | Faster | ~10-20% slower |\n",
    "| **Reliability** |  ~60-80% | - 100% |\n",
    "| **Use Case** | Simple JSON needed | Strict schema required |\n",
    "\n",
    "**When to Use JSON Mode:**\n",
    "- Quick prototyping\n",
    "- Flexible schema acceptable\n",
    "- Speed is critical\n",
    "- Manual validation is okay\n",
    "\n",
    "**When to Use Structured Outputs:**\n",
    "- Production APIs\n",
    "- Database storage\n",
    "- Type safety required\n",
    "- Integration with other systems\n",
    "- You need guarantees\n",
    "\n",
    "**Now let's see this in action...**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Step 0: Install Dependencies\n",
    "\n",
    "Run this cell to install all required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All dependencies installed!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install -q langgraph langchain-core langchain-openai python-dotenv\n",
    "\n",
    "print(\"All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Step 1: Setup Environment\n",
    "\n",
    "**Recommended:**\n",
    "Set up Holistic AI Bedrock Proxy API credentials in `.env`:\n",
    "\n",
    "```bash\n",
    "HOLISTIC_AI_TEAM_ID=tutorials_api\n",
    "HOLISTIC_AI_API_TOKEN=your-token-here\n",
    "```\n",
    "\n",
    "[API Guide](../assets/api-guide.pdf)\n",
    "\n",
    "**Alternative (Optional):**\n",
    "If you prefer OpenAI:\n",
    "\n",
    "```bash\n",
    "OPENAI_API_KEY=your-openai-api-key-here\n",
    "```\n",
    "\n",
    "**Note:** The tutorial uses Holistic AI Bedrock by default (recommended). OpenAI is optional - to use it, call get_chat_model(model_name, use_openai=True) and set OPENAI_API_KEY.\n",
    "\n",
    "**Note on Structured Output:** Basic structured output works with Holistic AI Bedrock. For advanced features like `with_structured_output()`, OpenAI may be needed as an alternative option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Loaded configuration from .env file\n",
      "âš ï¸  holistic_ai_bedrock.py not found - will use OpenAI only\n",
      "\n",
      "ðŸ”‘ API Key Status:\n",
      "  âœ… Holistic AI Bedrock credentials loaded (will use Bedrock)\n",
      "\n",
      "âœ… All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ============================================\n",
    "# OPTION 1: Set API keys directly (Quick Start)\n",
    "# ============================================\n",
    "# Uncomment and set your keys here:\n",
    "# Recommended: Holistic AI Bedrock\n",
    "# os.environ[\"HOLISTIC_AI_TEAM_ID\"] = \"tutorials_api\"\n",
    "# os.environ[\"HOLISTIC_AI_API_TOKEN\"] = \"your-token-here\"\n",
    "# Alternative: OpenAI (optional)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-openai-key-here\"\n",
    "\n",
    "# ============================================\n",
    "# OPTION 2: Load from .env file (Recommended)\n",
    "# ============================================\n",
    "env_path = Path('../.env')\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(\"ðŸ“„ Loaded configuration from .env file\")\n",
    "else:\n",
    "    print(\"âš ï¸  No .env file found - using environment variables or hardcoded keys\")\n",
    "\n",
    "# ============================================\n",
    "# Import Holistic AI Bedrock helper function\n",
    "# ============================================\n",
    "# Import from core module (recommended)\n",
    "import sys\n",
    "try:\n",
    "    sys.path.insert(0, '../core')\n",
    "    from react_agent.holistic_ai_bedrock import HolisticAIBedrockChat, get_chat_model\n",
    "    print(\"âœ… Holistic AI Bedrock helper function loaded\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸  Could not import from core - will use OpenAI only\")\n",
    "\n",
    "# Import official packages\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# Verify API keys\n",
    "print(\"\\nðŸ”‘ API Key Status:\")\n",
    "if os.getenv('HOLISTIC_AI_TEAM_ID') and os.getenv('HOLISTIC_AI_API_TOKEN'):\n",
    "    print(\"  âœ… Holistic AI Bedrock credentials loaded (will use Bedrock)\")\n",
    "elif os.getenv('OPENAI_API_KEY'):\n",
    "    print(\"  âš ï¸  OpenAI API key loaded (Bedrock credentials not set)\")\n",
    "    print(\"     ðŸ’¡ Tip: Set HOLISTIC_AI_TEAM_ID and HOLISTIC_AI_API_TOKEN to use Bedrock (recommended)\")\n",
    "else:\n",
    "    print(\"  âš ï¸  No API keys found\")\n",
    "    print(\"     Set Holistic AI Bedrock credentials (recommended) or OpenAI key\")\n",
    "\n",
    "print(\"âœ… All imports successful!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Step 2: Define a Pydantic Schema\n",
    "\n",
    "Let's define a structured format for analyzing technologies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema defined!\n",
      "   Fields: ['summary', 'key_points', 'pros', 'cons', 'confidence']\n",
      "   Validation: Built-in with Pydantic\n"
     ]
    }
   ],
   "source": [
    "# Define output schema\n",
    "class TechAnalysis(BaseModel):\n",
    "    \"\"\"Structured analysis of a technology.\"\"\"\n",
    "    summary: str = Field(description=\"One-sentence summary\")\n",
    "    key_points: List[str] = Field(description=\"3-5 key points\")\n",
    "    pros: List[str] = Field(description=\"2-3 advantages\")\n",
    "    cons: List[str] = Field(description=\"2-3 disadvantages\")\n",
    "    confidence: float = Field(description=\"Confidence score 0-100\", ge=0, le=100)\n",
    "\n",
    "print(\"Schema defined!\")\n",
    "print(f\"   Fields: {list(TechAnalysis.model_fields.keys())}\")\n",
    "print(f\"   Validation: Built-in with Pydantic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-schema-tips",
   "metadata": {},
   "source": [
    "### Common Mistakes with Pydantic Schemas\n",
    "\n",
    "When defining schemas, watch out for these common pitfalls:\n",
    "\n",
    "- **Mistake 1: Missing Field Descriptions**\n",
    "```python\n",
    "class BadSchema(BaseModel):\n",
    "    items: List[str]  # No description - LLM doesn't know what to put here!\n",
    "```\n",
    "\n",
    "- **Good Practice:**\n",
    "```python\n",
    "class GoodSchema(BaseModel):\n",
    "    items: List[str] = Field(description=\"List of main points from the analysis\")\n",
    "```\n",
    "\n",
    "- **Mistake 2: Vague Field Names**\n",
    "```python\n",
    "class BadSchema(BaseModel):\n",
    "    data: str  # What data? Too vague!\n",
    "```\n",
    "\n",
    "- **Good Practice:**\n",
    "```python\n",
    "class GoodSchema(BaseModel):\n",
    "    executive_summary: str = Field(description=\"1-2 sentence overview\")\n",
    "```\n",
    "\n",
    "- **Mistake 3: No Validation Constraints**\n",
    "```python\n",
    "class BadSchema(BaseModel):\n",
    "    score: float  # Could be negative or > 100!\n",
    "```\n",
    "\n",
    "- **Good Practice:**\n",
    "```python\n",
    "class GoodSchema(BaseModel):\n",
    "    score: float = Field(description=\"Quality score\", ge=0, le=100)\n",
    "```\n",
    "\n",
    "**Pro Tip:** The better your schema description, the better the LLM's output!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 3: Create LLM with Structured Output\n",
    "\n",
    "We use `.with_structured_output()` to bind the schema to the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LLM with structured output created!\n",
      "   Model: claude-3-5-sonnet (via Bedrock)\n",
      "   Output format: TechAnalysis (JSON)\n",
      "   Validation: Automatic with Pydantic\n"
     ]
    }
   ],
   "source": [
    "# Create base LLM\n",
    "# Use get_chat_model() - uses Holistic AI Bedrock by default (recommended)\n",
    "llm = get_chat_model(\"claude-3-5-sonnet\")  # Uses Holistic AI Bedrock (recommended)\n",
    "\n",
    "# Create LLM with structured output\n",
    "llm_structured = llm.with_structured_output(TechAnalysis)\n",
    "print(\"âœ… LLM with structured output created!\")\n",
    "print(\"   Model: claude-3-5-sonnet (via Bedrock)\")\n",
    "print(\"   Output format: TechAnalysis (JSON)\")\n",
    "print(\"   Validation: Automatic with Pydantic\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Step 4: Test Structured Output\n",
    "\n",
    "Let's ask the LLM to analyze a technology and get validated JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Analyze quantum computing technology\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured Output (Pydantic Object):\n",
      "======================================================================\n",
      "Summary: Quantum computing leverages quantum mechanical phenomena to perform complex calculations exponentially faster than classical computers for specific applications.\n",
      "\n",
      "Key Points (5):\n",
      "  1. Utilizes quantum bits (qubits) that can exist in multiple states simultaneously through superposition\n",
      "  2. Could revolutionize fields like cryptography, drug discovery, and optimization problems\n",
      "  3. Currently limited by challenges in maintaining qubit coherence and error correction\n",
      "  4. Major tech companies and governments are investing heavily in quantum computing research\n",
      "  5. May achieve quantum advantage for specific tasks within this decade\n",
      "\n",
      "Pros (3):\n",
      "  1. Exponentially faster processing for certain algorithms and problems\n",
      "  2. Potential to break current encryption methods and develop new secure communications\n",
      "  3. Could enable breakthroughs in materials science and drug development\n",
      "\n",
      "Cons (3):\n",
      "  1. Extremely sensitive to environmental interference and requires deep cooling\n",
      "  2. Currently has high error rates and limited qubit coherence time\n",
      "  3. Very expensive to develop and maintain quantum systems\n",
      "\n",
      "Confidence: 85.0%\n",
      "======================================================================\n",
      "Time: Time: 6.99s\n",
      "\n",
      "Type: TechAnalysis (automatically validated!)\n"
     ]
    }
   ],
   "source": [
    "# Test structured output\n",
    "question = \"Analyze quantum computing technology\"\n",
    "\n",
    "print(f\"Question: {question}\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "start_time = time.time()\n",
    "result = llm_structured.invoke(question)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(\"Structured Output (Pydantic Object):\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Summary: {result.summary}\\n\")\n",
    "print(f\"Key Points ({len(result.key_points)}):\")\n",
    "for i, point in enumerate(result.key_points, 1):\n",
    "    print(f\"  {i}. {point}\")\n",
    "\n",
    "print(f\"\\nPros ({len(result.pros)}):\")\n",
    "for i, pro in enumerate(result.pros, 1):\n",
    "    print(f\"  {i}. {pro}\")\n",
    "\n",
    "print(f\"\\nCons ({len(result.cons)}):\")\n",
    "for i, con in enumerate(result.cons, 1):\n",
    "    print(f\"  {i}. {con}\")\n",
    "\n",
    "print(f\"\\nConfidence: {result.confidence}%\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Time: {elapsed:.2f}s\")\n",
    "print(f\"\\nType: {type(result).__name__} (automatically validated!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Step 5: Compare Natural Text vs Structured Output\n",
    "\n",
    "Let's see the difference between natural text and structured output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "COMPARISON: Natural Text vs Structured Output\n",
      "======================================================================\n",
      "\n",
      "Natural Text Output:\n",
      "----------------------------------------------------------------------\n",
      "Here's a detailed analysis of quantum computing technology:\n",
      "\n",
      "Core Concepts:\n",
      "\n",
      "1. Quantum Bits (Qubits)\n",
      "- Unlike classical bits (0 or 1), qubits can exist in multiple states simultaneously (superposition)\n",
      "- Can be entangled with other qubits\n",
      "- Enables parallel processing of vast amounts of data\n",
      "\n",
      "2. Ke...\n",
      "----------------------------------------------------------------------\n",
      "Human-readable\n",
      "Conversational\n",
      "ERROR: Hard to parse programmatically\n",
      "Type: str\n",
      "\n",
      "Structured Output:\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"summary\": \"Quantum computing leverages quantum mechanical phenomena to perform complex calculations exponentially faster than classical computers for specific applications.\",\n",
      "  \"key_points\": [\n",
      "    \"Utilizes quantum bits (qubits) that can exist in multiple states simultaneously through superposi...\n",
      "----------------------------------------------------------------------\n",
      "Easy to parse and validate\n",
      "Type-safe with Pydantic\n",
      "Perfect for APIs and databases\n",
      "ERROR: Less conversational\n",
      "Type: TechAnalysis\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"COMPARISON: Natural Text vs Structured Output\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Natural text response\n",
    "result_natural = llm.invoke(question)\n",
    "\n",
    "print(\"\\nNatural Text Output:\")\n",
    "print(\"-\"*70)\n",
    "print(result_natural.content[:300] + \"...\")\n",
    "print(\"-\"*70)\n",
    "print(\"Human-readable\")\n",
    "print(\"Conversational\")\n",
    "print(\"ERROR: Hard to parse programmatically\")\n",
    "print(f\"Type: {type(result_natural.content).__name__}\")\n",
    "\n",
    "print(\"\\nStructured Output:\")\n",
    "print(\"-\"*70)\n",
    "result_json = result.model_dump_json(indent=2)\n",
    "print(result_json[:300] + \"...\")\n",
    "print(\"-\"*70)\n",
    "print(\"Easy to parse and validate\")\n",
    "print(\"Type-safe with Pydantic\")\n",
    "print(\"Perfect for APIs and databases\")\n",
    "print(\"ERROR: Less conversational\")\n",
    "print(f\"Type: {type(result).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Step 6: Working with Structured Data\n",
    "\n",
    "Once you have a Pydantic object, you can easily access fields and convert formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing Pydantic object fields:\n",
      "\n",
      "Summary: Quantum computing leverages quantum mechanical phenomena to perform complex calculations exponential...\n",
      "\n",
      "As dictionary: dict with 5 keys\n",
      "\n",
      "As JSON string (1080 characters):\n",
      "{\n",
      "  \"summary\": \"Quantum computing leverages quantum mechanical phenomena to perform complex calculations exponentially faster than classical computers for specific applications.\",\n",
      "  \"key_points\": [\n",
      "  ...\n",
      "\n",
      "Saved to /tmp/tech_analysis.json\n",
      "\n",
      "Loaded and validated: Confidence = 85.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accessing Pydantic object fields:\\n\")\n",
    "\n",
    "# Direct field access (with autocomplete!)\n",
    "print(f\"Summary: {result.summary[:100]}...\")\n",
    "\n",
    "# Convert to dictionary\n",
    "as_dict = result.model_dump()\n",
    "print(f\"\\nAs dictionary: {type(as_dict).__name__} with {len(as_dict)} keys\")\n",
    "\n",
    "# Convert to JSON string\n",
    "as_json = result.model_dump_json(indent=2)\n",
    "print(f\"\\nAs JSON string ({len(as_json)} characters):\")\n",
    "print(as_json[:200] + \"...\")\n",
    "\n",
    "# Save to file (example)\n",
    "with open('/tmp/tech_analysis.json', 'w') as f:\n",
    "    f.write(as_json)\n",
    "print(\"\\nSaved to /tmp/tech_analysis.json\")\n",
    "\n",
    "# Load and validate from JSON\n",
    "with open('/tmp/tech_analysis.json', 'r') as f:\n",
    "    loaded_data = json.load(f)\n",
    "    validated = TechAnalysis(**loaded_data)\n",
    "    print(f\"\\nLoaded and validated: Confidence = {validated.confidence}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-try-it",
   "metadata": {},
   "source": [
    "### Try It Yourself!\n",
    "\n",
    "Create your own schema for a different use case. Here are some ideas:\n",
    "\n",
    "**Idea 1: Movie Review Analysis**\n",
    "```python\n",
    "class MovieReview(BaseModel):\n",
    "    title: str = Field(description=\"Movie title\")\n",
    "    rating: float = Field(description=\"Rating out of 5 stars\", ge=0, le=5)\n",
    "    genres: List[str] = Field(description=\"List of genres\")\n",
    "    plot_summary: str = Field(description=\"Brief plot summary\")\n",
    "    recommendation: str = Field(description=\"Who should watch this movie\")\n",
    "```\n",
    "\n",
    "**Idea 2: Product Comparison**\n",
    "```python\n",
    "class ProductComparison(BaseModel):\n",
    "    product_name: str = Field(description=\"Product being analyzed\")\n",
    "    price_range: str = Field(description=\"Price category: budget/mid/premium\")\n",
    "    features: List[str] = Field(description=\"Key features\")\n",
    "    best_for: str = Field(description=\"Target audience or use case\")\n",
    "    alternatives: List[str] = Field(description=\"Similar products\")\n",
    "```\n",
    "\n",
    "**Exercise:** Try creating a schema for analyzing restaurant reviews, then test it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Step 7: Using Structured Output with Agents\n",
    "\n",
    "### The Proper Way: `response_format` Parameter\n",
    "\n",
    "Good news! You **CAN** use structured output with `create_react_agent` by using the `response_format` parameter:\n",
    "\n",
    "```python\n",
    "agent = create_react_agent(\n",
    "    llm,                           # Regular LLM (not .with_structured_output())\n",
    "    tools=[my_tool],               # Your tools\n",
    "    response_format=MySchema       # Your Pydantic schema\n",
    ")\n",
    "```\n",
    "\n",
    "**Key Differences:**\n",
    "\n",
    "| Approach | Code | Result Location |\n",
    "|----------|------|-----------------|\n",
    "| **Direct LLM** | `llm.with_structured_output(Schema)` | Returns Pydantic object |\n",
    "| **Agent** | `create_react_agent(..., response_format=Schema)` | `result['structured_response']` |\n",
    "\n",
    "### How It Works\n",
    "\n",
    "1. Agent uses tools to gather information\n",
    "2. Agent generates a natural language response\n",
    "3. A **second LLM call** structures the response according to your schema\n",
    "4. You get both: `messages` (conversation) and `structured_response` (Pydantic object)\n",
    "\n",
    "Let's see it in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent created with tools AND structured output!\n",
      "======================================================================\n",
      "\n",
      "Structured Response (TechAnalysis object):\n",
      "======================================================================\n",
      "Type: TechAnalysis\n",
      "\n",
      "Summary: Quantum computing is an emerging technology that leverages quantum mechanical principles like superposition and entanglement to solve complex computational problems beyond classical computing capabilities.\n",
      "\n",
      "Key Points (4):\n",
      "  1. Currently in NISQ (Noisy Intermediate-Scale Quantum) era with significant error correction challenges\n",
      "  2. Major tech companies like IBM, Google, and Rigetti are actively developing quantum systems\n",
      "  3. Primary applications include cryptography, drug discovery, and complex optimization problems\n",
      "  4. Operates using quantum mechanical principles fundamentally different from classical computing\n",
      "\n",
      "Pros (3):\n",
      "  1. Potential to solve previously intractable computational problems\n",
      "  2. Wide range of applications in security, science, and optimization\n",
      "  3. Strong industry investment and development from major tech companies\n",
      "\n",
      "Cons (3):\n",
      "  1. Still in early stages with significant technical limitations\n",
      "  2. Faces major challenges with noise and error correction\n",
      "  3. Current systems have limited reliability and practical applications\n",
      "\n",
      "Confidence: 85.0%\n",
      "\n",
      "Tool Calls Made:\n",
      "======================================================================\n",
      "  - get_tech_info({'tech_name': 'quantum computing'})\n",
      "\n",
      "TIP: Pattern: Agent uses tools â†’ Gathers info â†’ Returns structured output\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "# Define a tool\n",
    "@tool\n",
    "def get_tech_info(tech_name: str) -> str:\n",
    "    \"\"\"Get detailed information about a technology.\n",
    "    \n",
    "    Args:\n",
    "        tech_name: Name of the technology\n",
    "        \n",
    "    Returns:\n",
    "        Detailed technical information\n",
    "    \"\"\"\n",
    "    info_db = {\n",
    "        \"quantum computing\": \"Uses quantum mechanics principles like superposition and entanglement. Current systems are NISQ (noisy intermediate-scale quantum). Major players: IBM, Google, Rigetti. Applications: cryptography, drug discovery, optimization problems.\",\n",
    "        \"blockchain\": \"Distributed ledger with consensus mechanisms. Smart contracts enable programmable transactions. Proof-of-work vs proof-of-stake. Applications: cryptocurrency, supply chain tracking, decentralized identity.\",\n",
    "        \"ai\": \"Machine learning, deep neural networks, transformers. GPT models for NLP, CNNs for vision, reinforcement learning for control. Applications: language processing, image recognition, autonomous systems.\"\n",
    "    }\n",
    "    return info_db.get(tech_name.lower(), \"Technology not in database\")\n",
    "\n",
    "# Create agent with response_format\n",
    "agent_with_tools = create_react_agent(\n",
    "    llm,                          # Pass regular LLM\n",
    "    tools=[get_tech_info],        # Tools for the agent\n",
    "    response_format=TechAnalysis  # Schema for structured output\n",
    ")\n",
    "\n",
    "print(\"Agent created with tools AND structured output!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Invoke the agent\n",
    "result = agent_with_tools.invoke({\n",
    "    \"messages\": [(\"user\", \"Analyze quantum computing technology. Use the get_tech_info tool to gather information.\")]\n",
    "})\n",
    "\n",
    "# Access the structured response\n",
    "structured = result['structured_response']\n",
    "\n",
    "print(\"\\nStructured Response (TechAnalysis object):\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Type: {type(structured).__name__}\")\n",
    "print(f\"\\nSummary: {structured.summary}\")\n",
    "print(f\"\\nKey Points ({len(structured.key_points)}):\")\n",
    "for i, point in enumerate(structured.key_points, 1):\n",
    "    print(f\"  {i}. {point}\")\n",
    "\n",
    "print(f\"\\nPros ({len(structured.pros)}):\")\n",
    "for i, pro in enumerate(structured.pros, 1):\n",
    "    print(f\"  {i}. {pro}\")\n",
    "\n",
    "print(f\"\\nCons ({len(structured.cons)}):\")\n",
    "for i, con in enumerate(structured.cons, 1):\n",
    "    print(f\"  {i}. {con}\")\n",
    "\n",
    "print(f\"\\nConfidence: {structured.confidence}%\")\n",
    "\n",
    "# Also show tool usage\n",
    "print(\"\\nTool Calls Made:\")\n",
    "print(\"=\"*70)\n",
    "tool_calls = [msg for msg in result['messages'] if hasattr(msg, 'tool_calls') and msg.tool_calls]\n",
    "if tool_calls:\n",
    "    for msg in tool_calls:\n",
    "        for tc in msg.tool_calls:\n",
    "            print(f\"  - {tc['name']}({tc['args']})\")\n",
    "else:\n",
    "    print(\"  No tools were called\")\n",
    "\n",
    "print(\"\\nTIP: Pattern: Agent uses tools â†’ Gathers info â†’ Returns structured output\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-troubleshooting",
   "metadata": {},
   "source": [
    "## Troubleshooting Common Issues### Issue 1: Validation Error```pydantic.ValidationError: 1 validation error for TechAnalysisconfidence  Input should be less than or equal to 100```**Solution:** The LLM returned a value outside your constraints. Check your Field() constraints (ge, le, etc.)### Issue 2: Missing Required Fields```pydantic.ValidationError: Field required```**Solution:** Make fields optional with `Optional[...]` or provide defaults:```pythonfrom typing import Optionalclass FlexibleSchema(BaseModel):    required_field: str    optional_field: Optional[str] = None    field_with_default: int = 0```### Issue 3: LLM Returns Text Instead of JSON```JSONDecodeError: Expecting value```**Solution:** Ensure you're using `.with_structured_output()` and that the model supports function calling (claude-3-5-sonnet does!).### Issue 4: Output is Too SlowStructured output requires the LLM to format JSON, which can be slower.**Solution:** - Use structured output only when you need it- For simple extractions, consider using natural text with regex parsing- For production, consider caching results### Debugging Tips1. **Check the schema:** Print `YourSchema.model_json_schema()` to see what the LLM receives2. **Test with simple prompts:** Start with easy questions before complex ones3. **Validate manually:** Try `YourSchema(**test_data)` with sample data4. **Check field descriptions:** Make sure they're clear and specific"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-hands-on",
   "metadata": {},
   "source": [
    "## Hands-On Exercise\n",
    "\n",
    "Try this exercise to practice what you've learned:\n",
    "\n",
    "### Task: Build a News Article Analyzer\n",
    "\n",
    "Create a Pydantic schema and LLM that analyzes news articles and returns:\n",
    "- Article category (politics/tech/sports/entertainment/other)\n",
    "- Sentiment (positive/negative/neutral)\n",
    "- Key entities mentioned (people, organizations, locations)\n",
    "- Main topics (3-5 bullet points)\n",
    "- Reading difficulty (easy/medium/hard)\n",
    "\n",
    "**Starter Code:**\n",
    "```python\n",
    "class NewsAnalysis(BaseModel):\n",
    "    category: str = Field(description=\"Article category\")\n",
    "    sentiment: str = Field(description=\"Overall sentiment\")\n",
    "    # Add more fields here!\n",
    "\n",
    "llm_news = llm.with_structured_output(NewsAnalysis)\n",
    "result = llm_news.invoke(\"Analyze this article: [paste article text]\")\n",
    "```\n",
    "\n",
    "**Bonus Challenge:** Add validation to ensure category is one of the valid options using Pydantic's `Literal` type!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## SummaryCongratulations! You've learned:### Key Concepts1. **Pydantic Schemas** - Define structured output formats with validation2. **with_structured_output()** - Bind schemas to LLMs for automatic JSON parsing3. **Type Safety** - Get validated Pydantic objects instead of raw strings4. **Comparison** - Understand trade-offs between natural text and structured output### When to Use Each#### Natural Text (Default)- Chatbots and conversational interfaces- Reports and explanations- Human-facing applications- When flexibility is needed#### Structured Output (with Pydantic)- API responses- Data extraction and transformation- Database storage- Integration with other systems- When type safety and validation matter### Important Notes- Structured output may be slightly slower due to JSON formatting- The LLM must support function calling (claude-3-5-sonnet does!)- Validation happens automatically with Pydantic- Field descriptions help the LLM understand what to generate---**Pro Tip**: Define reusable Pydantic schemas for common tasks (e.g., `SearchResult`, `Analysis`, `Summary`) and reuse them across your application!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}