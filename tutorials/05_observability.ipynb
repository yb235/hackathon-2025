{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1840effa",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"../assets/images/hackathon.png\" alt=\"Holistic AI Hackathon Logo\" width=\"600\"/>\n",
    "</div>\n",
    "\n",
    "**Event**: [hackathon.holisticai.com](https://hackathon.holisticai.com)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Tutorial 5: Observability\n",
    "\n",
    "**Master deep observability and debugging for production agents**\n",
    "\n",
    "Learn to enable LangSmith tracing, view detailed execution traces, add metadata for filtering, collect user feedback, and query runs programmatically.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. Enable LangSmith tracing\n",
    "2. View detailed execution traces\n",
    "3. Add metadata for filtering\n",
    "4. Collect user feedback\n",
    "5. Query runs programmatically\n",
    "6. Monitor complex agents with tools\n",
    "\n",
    "## Why Observe?\n",
    "\n",
    "- **Debugging** - Understand what your agent is doing\n",
    "- **Quality assurance** - Track user satisfaction\n",
    "- **Performance** - Identify bottlenecks\n",
    "- **Transparency** - See agent decision-making process\n",
    "- **Production monitoring** - Catch issues before users do\n",
    "- **Performance optimization** - Find and fix bottlenecks\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Basic Python knowledge\n",
    "- Recommended: Completed tutorials 01-03\n",
    "- Time: ~20 minutes\n",
    "- **Holistic AI Bedrock API** (recommended) - Credentials will be provided during the hackathon event\n",
    "- **OpenAI API key** (optional alternative) - Get at https://platform.openai.com/api-keys\n",
    "- **LangSmith API key** (required for this tutorial) - Get at https://smith.langchain.com (free)\n",
    "\n",
    "**API Guide**: [../assets/api-guide.pdf](../assets/api-guide.pdf)\n",
    "\n",
    "**Note:** This tutorial is completely self-contained and uses only official packages!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Step 0: Install Dependencies\n",
    "\n",
    "Run this cell to install all required packages for LangSmith observability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom pathlib import Path\nfrom dotenv import load_dotenv\n\n# Load from .env file in parent directory\nenv_path = Path('../.env')\nif env_path.exists():\n    load_dotenv(env_path)\n    print(\"ðŸ“„ Loaded configuration from .env file\")\nelse:\n    print(\"âš ï¸  No .env file found - using environment variables\")\n\n# Verify API keys\nprint(\"\\nðŸ”‘ API Key Status:\")\nif os.getenv('HOLISTIC_AI_TEAM_ID') and os.getenv('HOLISTIC_AI_API_TOKEN'):\n    print(\"  âœ… Holistic AI Bedrock credentials loaded\")\nelif os.getenv('OPENAI_API_KEY'):\n    print(\"  âš ï¸  OpenAI API key loaded\")\nelse:\n    print(\"  âš ï¸  No API keys found\")\n\nif os.getenv('LANGSMITH_API_KEY'):\n    print(\"  âœ… LangSmith API key loaded\")\n    os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n    os.environ[\"LANGSMITH_PROJECT\"] = \"hackathon-2025\"\nelse:\n    print(\"  âš ï¸  LangSmith API key not found - tracing disabled\")\n\nprint(\"\\nðŸ“ Working directory:\", Path.cwd())\n\n# Import Holistic AI Bedrock helper\nimport sys\ntry:\n    sys.path.insert(0, '../core')\n    from react_agent.holistic_ai_bedrock import get_chat_model\n    print(\"\\nâœ… Holistic AI Bedrock helper loaded\")\nexcept ImportError:\n    print(\"\\nâš ï¸  Could not import from core - will use OpenAI only\")\n\n# Import official packages\nfrom langgraph.prebuilt import create_react_agent\nfrom langchain_core.messages import HumanMessage\n\nprint(\"\\nâœ… All imports successful!\")\n"
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup\n",
    "\n",
    "You'll need API keys for this tutorial:\n",
    "\n",
    "### Recommended: Holistic AI Bedrock API\n",
    "Credentials will be provided during the hackathon event.\n",
    "\n",
    "### Optional: OpenAI API Key\n",
    "Get your key at: https://platform.openai.com/api-keys (alternative)\n",
    "\n",
    "### Required: LangSmith API Key\n",
    "1. Sign up for free at: https://smith.langchain.com\n",
    "2. Go to Settings > API Keys\n",
    "3. Create a new API key\n",
    "\n",
    "**Note:** This tutorial requires LangSmith for full functionality. Holistic AI Bedrock is recommended, OpenAI is optional.\n",
    "\n",
    "### Configure Your Keys\n",
    "\n",
    "**Option 1: Direct Setup (Quick Start)**\n",
    "- Uncomment lines in the cell below and add your keys\n",
    "\n",
    "**Option 2: Environment File (Recommended)**\n",
    "- Create a `.env` file in the parent directory with:\n",
    "```\n",
    "HOLISTIC_AI_TEAM_ID=your-team-id-here\n",
    "HOLISTIC_AI_API_TOKEN=your-api-token-here\n",
    "OPENAI_API_KEY=your-openai-key-here  # Optional\n",
    "LANGSMITH_API_KEY=your-langsmith-key-here\n",
    "LANGSMITH_PROJECT=hackathon-2026\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded configuration from .env file\n",
      "âœ… Holistic AI Bedrock helper function loaded\n",
      "âœ… Holistic AI Bedrock credentials loaded (will use Bedrock)\n",
      "OpenAI API key loaded: sk-proj-10...\n",
      "LangSmith API key loaded: lsv2_pt_10...\n",
      "  LangSmith project: pr-loyal-quota-66\n",
      "  LangSmith tracing will be fully functional!\n",
      "\n",
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import uuid\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ============================================\n",
    "# OPTION 1: Set API keys directly (Quick Start)\n",
    "# ============================================\n",
    "# Uncomment and set your keys here:\n",
    "# Recommended: Holistic AI Bedrock\n",
    "# os.environ[\"HOLISTIC_AI_TEAM_ID\"] = \"your-team-id-here\"\n",
    "# os.environ[\"HOLISTIC_AI_API_TOKEN\"] = \"your-api-token-here\"\n",
    "# Optional: OpenAI\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-openai-key-here\"\n",
    "# os.environ[\"LANGSMITH_API_KEY\"] = \"your-langsmith-key-here\"  # Required for LangSmith tracing\n",
    "# os.environ[\"LANGSMITH_PROJECT\"] = \"hackathon-2026\"  # Optional\n",
    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\"  # Required for LangGraph tracing\n",
    "# os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"  # Optional (default)\n",
    "\n",
    "# ============================================\n",
    "# OPTION 2: Load from .env file (Recommended)\n",
    "# ============================================\n",
    "env_path = Path('../.env')\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(\"Loaded configuration from .env file\")\n",
    "else:\n",
    "    print(\"WARNING: No .env file found - using environment variables or hardcoded keys\")\n",
    "\n",
    "# Import official packages\n",
    "# Import Holistic AI Bedrock helper function\n",
    "# Import from core module\n",
    "try:\n",
    "    import sys\n",
    "    sys.path.insert(0, '../core')\n",
    "    from react_agent.holistic_ai_bedrock import HolisticAIBedrockChat, get_chat_model\n",
    "    print(\"âœ… Holistic AI Bedrock helper function loaded\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸  Could not import from core\")\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "# Optional: OpenAI (if not using Bedrock)\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# Import monitoring tools\n",
    "import tiktoken\n",
    "from codecarbon import EmissionsTracker\n",
    "from langsmith import Client\n",
    "\n",
    "# Check API keys (Holistic AI Bedrock recommended, OpenAI optional)\n",
    "# Check Holistic AI Bedrock (recommended)\n",
    "if os.getenv('HOLISTIC_AI_TEAM_ID') and os.getenv('HOLISTIC_AI_API_TOKEN'):\n",
    "    print(\"âœ… Holistic AI Bedrock credentials loaded (will use Bedrock)\")\n",
    "\n",
    "# Check OpenAI (optional)\n",
    "if os.getenv('OPENAI_API_KEY'):\n",
    "    key_preview = os.getenv('OPENAI_API_KEY')[:10] + \"...\"\n",
    "    print(f\"OpenAI API key loaded: {key_preview}\")\n",
    "else:\n",
    "    print(\"â„¹ï¸  OpenAI API key not found - optional, will use Bedrock if available\")\n",
    "\n",
    "# Check LangSmith API key (required for this tutorial)\n",
    "if os.getenv('LANGSMITH_API_KEY'):\n",
    "    ls_key = os.getenv('LANGSMITH_API_KEY')[:10] + \"...\"\n",
    "    print(f\"LangSmith API key loaded: {ls_key}\")\n",
    "    \n",
    "    # Set required LangGraph tracing environment variables if not already set\n",
    "    if not os.getenv('LANGSMITH_TRACING'):\n",
    "        os.environ['LANGSMITH_TRACING'] = 'true'\n",
    "        print(\"  LANGSMITH_TRACING set to 'true' (required for LangGraph tracing)\")\n",
    "    \n",
    "    if not os.getenv('LANGSMITH_ENDPOINT'):\n",
    "        os.environ['LANGSMITH_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "        print(\"  LANGSMITH_ENDPOINT set to 'https://api.smith.langchain.com'\")\n",
    "    \n",
    "    langsmith_project = os.getenv('LANGSMITH_PROJECT', 'default')\n",
    "    print(f\"  LangSmith project: {langsmith_project}\")\n",
    "    print(\"  LangSmith tracing will be fully functional!\")\n",
    "else:\n",
    "    print(\"ERROR: LangSmith API key not found - tracing will not work!\")\n",
    "    print(\"  Get a free key at: https://smith.langchain.com\")\n",
    "    print(\"  This tutorial requires LangSmith to function properly!\")\n",
    "\n",
    "print(\"\\nAll imports successful!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Observability\n",
    "\n",
    "Deep tracing and debugging for production agents.\n",
    "\n",
    "**Note:** This section requires a LangSmith API key. If you don't have one, you can still read through to understand the concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Step 2: Enable LangSmith Tracing\n",
    "\n",
    "LangGraph agents automatically trace to LangSmith when the required environment variables are set:\n",
    "- `LANGSMITH_API_KEY` - Your LangSmith API key\n",
    "- `LANGSMITH_TRACING=true` - Required to enable automatic tracing\n",
    "- `LANGSMITH_ENDPOINT` - LangSmith API endpoint (default: https://api.smith.langchain.com)\n",
    "- `LANGSMITH_PROJECT` - Project name for organizing traces (optional)\n",
    "\n",
    "**Note:** These are automatically set in Step 1 when `LANGSMITH_API_KEY` is detected. No additional configuration needed!\n",
    "\n",
    "\n",
    "Every time you call `agent.invoke()`, a trace is automatically sent to LangSmith with:\n",
    "- Full conversation history\n",
    "- Token usage breakdown\n",
    "- Latency at each step\n",
    "- Model parameters used\n",
    "- Tool calls and outputs (if using tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cell-19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent created with automatic LangSmith tracing!\n",
      "  Model: claude-3-5-sonnet (via Bedrock if available)\n",
      "  Project: pr-loyal-quota-66\n",
      "\n",
      "Every agent.invoke() call will be traced to:\n",
      "  https://smith.langchain.com\n"
     ]
    }
   ],
   "source": [
    "# Create agent with automatic LangSmith tracing\n",
    "# Use get_chat_model() - uses Holistic AI Bedrock by default (recommended)\n",
    "llm_traced = get_chat_model(\"claude-3-5-sonnet\")  # Uses Holistic AI Bedrock (recommended)\n",
    "agent_traced = create_react_agent(llm_traced, tools=[])\n",
    "\n",
    "langsmith_project = os.getenv('LANGSMITH_PROJECT', 'default')\n",
    "\n",
    "print(\"Agent created with automatic LangSmith tracing!\")\n",
    "print(f\"  Model: claude-3-5-sonnet (via Bedrock if available)\")\n",
    "print(f\"  Project: {langsmith_project}\")\n",
    "print(f\"\\nEvery agent.invoke() call will be traced to:\")\n",
    "print(f\"  https://smith.langchain.com\")\n",
    "\n",
    "if not os.getenv('LANGSMITH_API_KEY'):\n",
    "    print(\"\\nWARNING: No LangSmith API key found!\")\n",
    "    print(\"  Tracing will not work without it.\")\n",
    "    print(\"  Get a free key at: https://smith.langchain.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## Step 3: View Traces in LangSmith UI\n",
    "\n",
    "Let's run a query and view the trace in LangSmith.\n",
    "\n",
    "The trace will show you:\n",
    "- Input messages\n",
    "- Model responses\n",
    "- Token counts (prompt and completion)\n",
    "- Latency for each step\n",
    "- Total cost estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cell-21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: b844fabd-03fc-4e92-99e0-db3815d6718b\n",
      "\n",
      "Running agent...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "  Machine learning is a branch of artificial intelligence where computer systems learn patterns from data to make predictions or decisions without being explicitly programmed.\n",
      "\n",
      "Latency: 1.58s\n",
      "\n",
      "======================================================================\n",
      "View this trace in LangSmith:\n",
      "  https://smith.langchain.com\n",
      "  Project: pr-loyal-quota-66\n",
      "  Search for run ID: b844fabd-03fc-4e92-99e0-db3815d6718b\n",
      "\n",
      "The trace shows:\n",
      "  - Full conversation history\n",
      "  - Token usage breakdown\n",
      "  - Latency at each step\n",
      "  - Model parameters used\n"
     ]
    }
   ],
   "source": [
    "# Generate a unique run ID for tracking\n",
    "run_id = str(uuid.uuid4())\n",
    "\n",
    "print(f\"Run ID: {run_id}\")\n",
    "print(\"\\nRunning agent...\\n\")\n",
    "\n",
    "# Run the agent with metadata\n",
    "start_time = time.time()\n",
    "result = agent_traced.invoke(\n",
    "    {\"messages\": [(\"user\", \"Explain machine learning in one sentence.\")]},\n",
    "    {\"run_id\": run_id, \"tags\": [\"tutorial\", \"observability\"]}\n",
    ")\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "response = result['messages'][-1].content\n",
    "\n",
    "print(\"Response:\")\n",
    "print(f\"  {response}\")\n",
    "print(f\"\\nLatency: {elapsed:.2f}s\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"View this trace in LangSmith:\")\n",
    "\n",
    "# Try to get the exact URL\n",
    "if os.getenv('LANGSMITH_API_KEY'):\n",
    "    try:\n",
    "        ls_client = Client()\n",
    "        run_url = ls_client.read_run(run_id).url\n",
    "        print(f\"  {run_url}\")\n",
    "    except Exception:\n",
    "        print(f\"  https://smith.langchain.com\")\n",
    "        print(f\"  Project: {langsmith_project}\")\n",
    "        print(f\"  Search for run ID: {run_id}\")\n",
    "else:\n",
    "    print(\"  (LangSmith API key not set - tracing disabled)\")\n",
    "\n",
    "print(\"\\nThe trace shows:\")\n",
    "print(\"  - Full conversation history\")\n",
    "print(\"  - Token usage breakdown\")\n",
    "print(\"  - Latency at each step\")\n",
    "print(\"  - Model parameters used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## Step 4: Add Metadata for Filtering\n",
    "\n",
    "Metadata helps you filter and analyze runs in production. You can add custom metadata to track:\n",
    "- User IDs\n",
    "- Session IDs\n",
    "- Feature flags\n",
    "- A/B test variants\n",
    "- Environment (dev/staging/prod)\n",
    "\n",
    "This makes it easy to:\n",
    "- Filter runs by user\n",
    "- Compare A/B test variants\n",
    "- Debug user-specific issues\n",
    "- Track feature adoption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cell-23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run completed with metadata:\n",
      "  user_id: demo_user_123\n",
      "  model: claude-3-5-sonnet\n",
      "  version: v1.0\n",
      "  environment: tutorial\n",
      "\n",
      "View at: https://smith.langchain.com/o/1961c9a6-cf5c-4882-86b8-9028e1683672/projects/p/c17bf9b5-dbc0-4a35-8f65-5adc9a5b2911/r/d99078fc-ca14-478c-8053-bed4b2082612?trace_id=d99078fc-ca14-478c-8053-bed4b2082612&start_time=2025-11-11T00:37:04.628442\n"
     ]
    }
   ],
   "source": [
    "# Run with rich metadata\n",
    "run_id = str(uuid.uuid4())\n",
    "metadata = {\n",
    "    \"user_id\": \"demo_user_123\",\n",
    "    \"model\": \"claude-3-5-sonnet\",  # Using Bedrock\n",
    "    \"version\": \"v1.0\",\n",
    "    \"environment\": \"tutorial\"\n",
    "}\n",
    "\n",
    "result = agent_traced.invoke(\n",
    "    {\"messages\": [(\"user\", \"What is quantum computing?\")]},\n",
    "    {\"run_id\": run_id, \"tags\": [\"tutorial\", \"metadata-demo\"], \"metadata\": metadata}\n",
    ")\n",
    "\n",
    "print(\"Run completed with metadata:\")\n",
    "for key, value in metadata.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Get URL from LangSmith\n",
    "if os.getenv('LANGSMITH_API_KEY'):\n",
    "    try:\n",
    "        ls_client = Client()\n",
    "        run_url = ls_client.read_run(run_id).url\n",
    "        print(f\"\\nView at: {run_url}\")\n",
    "    except Exception:\n",
    "        print(f\"\\nView in LangSmith:\")\n",
    "        print(f\"  https://smith.langchain.com\")\n",
    "        print(f\"  Project: {langsmith_project}\")\n",
    "        print(f\"  Run ID: {run_id}\")\n",
    "else:\n",
    "    print(\"\\n(LangSmith API key not set - tracing disabled)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## Step 5: Collect User Feedback\n",
    "\n",
    "User feedback is crucial for improving your agents. LangSmith makes it easy to:\n",
    "- Collect thumbs up/down feedback\n",
    "- Add user comments\n",
    "- Track satisfaction over time\n",
    "- Find problematic runs\n",
    "\n",
    "In production, you would collect this feedback from your UI and send it to LangSmith."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cell-25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedback logged successfully!\n",
      "  Score: thumbs up\n",
      "  Comment: Great explanation!\n",
      "\n",
      "In LangSmith, you can:\n",
      "  - Filter runs by feedback score\n",
      "  - Identify problematic runs\n",
      "  - Track user satisfaction trends\n"
     ]
    }
   ],
   "source": [
    "if os.getenv('LANGSMITH_API_KEY'):\n",
    "    try:\n",
    "        ls_client = Client()\n",
    "        \n",
    "        # Simulate user feedback (in production, this would come from UI)\n",
    "        user_score = 1.0  # 1.0 = thumbs up, 0.0 = thumbs down\n",
    "        user_comment = \"Great explanation!\"\n",
    "        \n",
    "        # Log feedback\n",
    "        ls_client.create_feedback(\n",
    "            run_id,\n",
    "            key=\"user-score\",\n",
    "            score=user_score,\n",
    "            comment=user_comment\n",
    "        )\n",
    "        \n",
    "        print(\"Feedback logged successfully!\")\n",
    "        print(f\"  Score: {'thumbs up' if user_score > 0.5 else 'thumbs down'}\")\n",
    "        print(f\"  Comment: {user_comment}\")\n",
    "        print(\"\\nIn LangSmith, you can:\")\n",
    "        print(\"  - Filter runs by feedback score\")\n",
    "        print(\"  - Identify problematic runs\")\n",
    "        print(\"  - Track user satisfaction trends\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not log feedback: {e}\")\n",
    "        print(\"Make sure you have a valid LangSmith API key\")\n",
    "else:\n",
    "    print(\"LangSmith API key not set - feedback logging disabled\")\n",
    "    print(\"\\nIn production, user feedback helps you:\")\n",
    "    print(\"  - Identify problematic responses\")\n",
    "    print(\"  - Track satisfaction over time\")\n",
    "    print(\"  - Find runs that need investigation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## Step 6: Query Runs Programmatically\n",
    "\n",
    "Use the LangSmith SDK to query and analyze runs. This is useful for:\n",
    "- Building custom dashboards\n",
    "- Automated monitoring\n",
    "- Data analysis\n",
    "- Quality assurance\n",
    "\n",
    "You can filter runs by:\n",
    "- Tags, metadata, feedback\n",
    "- Time range, latency, tokens\n",
    "- Error status, model used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cell-27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recent Runs (last hour):\n",
      "======================================================================\n",
      "\n",
      "1. Run ID: 38a302e1-f11c-4c67-aac2-601e6645c214\n",
      "   Status: success\n",
      "   Latency: 6.92s\n",
      "\n",
      "2. Run ID: 2bfac2d1-ddf0-4697-a1b7-9e895afc1e48\n",
      "   Status: success\n",
      "   Latency: 0.00s\n",
      "\n",
      "3. Run ID: 15c7dc8b-b16b-4099-9f14-239fd40d0839\n",
      "   Status: success\n",
      "   Latency: 6.92s\n",
      "\n",
      "4. Run ID: 554105e7-bf59-4147-a7c8-f30f9500eadf\n",
      "   Status: success\n",
      "   Latency: 6.92s\n",
      "\n",
      "5. Run ID: edcd6fdd-ba92-4e68-a824-20173f72aa48\n",
      "   Status: success\n",
      "   Latency: 6.92s\n",
      "\n",
      "You can query by:\n",
      "  - Tags, metadata, feedback\n",
      "  - Time range, latency, tokens\n",
      "  - Error status, model used\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "if os.getenv('LANGSMITH_API_KEY'):\n",
    "    try:\n",
    "        ls_client = Client()\n",
    "        \n",
    "        # Query recent runs from our project\n",
    "        recent_runs = ls_client.list_runs(\n",
    "            project_name=langsmith_project,\n",
    "            start_time=datetime.now() - timedelta(hours=1),\n",
    "            limit=5\n",
    "        )\n",
    "        \n",
    "        print(\"Recent Runs (last hour):\")\n",
    "        print(\"=\"*70)\n",
    "        for i, run in enumerate(recent_runs, 1):\n",
    "            print(f\"\\n{i}. Run ID: {run.id}\")\n",
    "            print(f\"   Status: {run.status}\")\n",
    "            print(f\"   Latency: {run.latency:.2f}s\" if run.latency else \"   Latency: N/A\")\n",
    "            if run.feedback_stats:\n",
    "                print(f\"   Feedback: {run.feedback_stats}\")\n",
    "            if i >= 5:\n",
    "                break\n",
    "        \n",
    "        print(\"\\nYou can query by:\")\n",
    "        print(\"  - Tags, metadata, feedback\")\n",
    "        print(\"  - Time range, latency, tokens\")\n",
    "        print(\"  - Error status, model used\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not query runs: {e}\")\n",
    "        print(\"Make sure you have a valid LangSmith API key\")\n",
    "else:\n",
    "    print(\"LangSmith API key not set - querying disabled\")\n",
    "    print(\"\\nIn production, programmatic querying enables:\")\n",
    "    print(\"  - Custom dashboards\")\n",
    "    print(\"  - Automated alerts\")\n",
    "    print(\"  - Quality assurance checks\")\n",
    "    print(\"  - Performance analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "## Step 7: Monitor Complex Agent with Tools\n",
    "\n",
    "Let's trace a more complex agent that uses tools. This shows how LangSmith helps you understand:\n",
    "- Agent reasoning steps\n",
    "- Tool selection and execution\n",
    "- Tool outputs\n",
    "- Final synthesis\n",
    "\n",
    "This is especially valuable when debugging why an agent chose certain tools or produced unexpected results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cell-29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex Run ID: 0ab39e2f-5283-4f55-a3ac-20e46671cbec\n",
      "\n",
      "Running agent with tool...\n",
      "\n",
      "Response: Today's date is 2025-11-11.\n",
      "\n",
      "Complex trace complete!\n",
      "\n",
      "Find trace in LangSmith:\n",
      "  https://smith.langchain.com\n",
      "  Project: pr-loyal-quota-66\n",
      "  Search run ID: 0ab39e2f-5283-4f55-a3ac-20e46671cbec\n",
      "\n",
      "The trace shows:\n",
      "  - Agent reasoning steps\n",
      "  - Tool calls (get_current_date)\n",
      "  - Tool outputs\n",
      "  - Final response synthesis\n"
     ]
    }
   ],
   "source": [
    "# Create a simple demo tool\n",
    "@tool\n",
    "def get_current_date(format: str = \"YYYY-MM-DD\") -> str:\n",
    "    \"\"\"Get the current date in the specified format.\"\"\"\n",
    "    from datetime import datetime\n",
    "    return datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Create agent with tool\n",
    "# Use get_chat_model() - uses Holistic AI Bedrock by default (recommended)\n",
    "llm_with_tool = get_chat_model(\"claude-3-5-sonnet\")  # Uses Holistic AI Bedrock (recommended)\n",
    "agent_with_tool = create_react_agent(llm_with_tool, tools=[get_current_date])\n",
    "\n",
    "run_id = str(uuid.uuid4())\n",
    "print(f\"Complex Run ID: {run_id}\")\n",
    "print(\"\\nRunning agent with tool...\\n\")\n",
    "\n",
    "result = agent_with_tool.invoke(\n",
    "    {\"messages\": [(\"user\", \"What is today's date?\")]},\n",
    "    {\"run_id\": run_id, \"tags\": [\"tool-use\", \"complex\"]}\n",
    ")\n",
    "\n",
    "response = result['messages'][-1].content\n",
    "print(f\"Response: {response}\")\n",
    "\n",
    "print(\"\\nComplex trace complete!\")\n",
    "\n",
    "# Get URL\n",
    "if os.getenv('LANGSMITH_API_KEY'):\n",
    "    try:\n",
    "        ls_client = Client()\n",
    "        run_url = ls_client.read_run(run_id).url\n",
    "        print(f\"\\nView detailed trace: {run_url}\")\n",
    "    except Exception:\n",
    "        print(f\"\\nFind trace in LangSmith:\")\n",
    "        print(f\"  https://smith.langchain.com\")\n",
    "        print(f\"  Project: {langsmith_project}\")\n",
    "        print(f\"  Search run ID: {run_id}\")\n",
    "else:\n",
    "    print(\"\\n(LangSmith API key not set - tracing disabled)\")\n",
    "\n",
    "print(\"\\nThe trace shows:\")\n",
    "print(\"  - Agent reasoning steps\")\n",
    "print(\"  - Tool calls (get_current_date)\")\n",
    "print(\"  - Tool outputs\")\n",
    "print(\"  - Final response synthesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-part-b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "Congratulations! You've mastered observability and debugging with LangSmith.\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "1. **Enable Tracing** - Automatic tracing with LangSmith API key\n",
    "2. **View Traces** - See full execution in LangSmith UI\n",
    "3. **Add Metadata** - Filter by user, environment, variant\n",
    "4. **Collect Feedback** - Track user satisfaction\n",
    "5. **Query Runs** - Programmatic analysis with LangSmith SDK\n",
    "6. **Debug Complex Agents** - Understand tool usage and reasoning\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "- LangSmith provides automatic tracing for LangGraph agents\n",
    "- Metadata enables powerful filtering and analysis\n",
    "- User feedback helps identify problematic runs\n",
    "- Programmatic querying enables custom dashboards\n",
    "- Tracing shows full conversation history, token usage, and latency\n",
    "\n",
    "### Production Best Practices\n",
    "\n",
    "1. **Always add metadata** - Makes filtering and analysis easier\n",
    "2. **Collect user feedback** - Essential for improvement\n",
    "3. **Set up alerts** - Monitor error rates, latency spikes, costs\n",
    "4. **Regular analysis** - Review traces to find optimization opportunities\n",
    "5. **Use tags** - Organize runs by feature, version, environment\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "Continue your learning journey:\n",
    "- **04_model_monitoring.ipynb** - Learn performance monitoring and cost tracking\n",
    "- **06_benchmark_evaluation.ipynb** - Test agents on PhD-level questions\n",
    "- **Advanced**: Set up production monitoring dashboards\n",
    "- **Advanced**: Create automated quality assurance pipelines\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [LangSmith Documentation](https://docs.smith.langchain.com)\n",
    "- [Observability Guide](https://docs.smith.langchain.com/observability)\n",
    "- [LangGraph Tracing](https://langchain-ai.github.io/langgraph/how-tos/tracing/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}