{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"../assets/images/hackathon.png\" alt=\"Holistic AI Hackathon Logo\" width=\"600\"/>\n",
    "</div>\n",
    "\n",
    "**Event**: [hackathon.holisticai.com](https://hackathon.holisticai.com)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Building ReAct Agents with LangGraph\n",
    "\n",
    "**Learn to build intelligent agents using LangGraph's prebuilt ReAct pattern**\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **Understand**: What is a ReAct agent and how it differs from direct LLM calls\n",
    "2. **Build**: Your first ReAct agent using LangGraph's official implementation\n",
    "3. **Add Tools**: Integrate Valyu AI search for real-time information\n",
    "4. **Compare**: Agent performance with and without tools\n",
    "\n",
    "## What is ReAct?\n",
    "\n",
    "**ReAct** = **Reasoning** + **Acting**\n",
    "\n",
    "- Traditional approach (2022): LLM generates explicit \"Thought:\", \"Action:\", \"Observation:\" steps in text\n",
    "- Modern approach (2023-2025): LLMs use **function calling** - structured tool execution built into the model API\n",
    "- This tutorial uses the **modern approach** with LangGraph's prebuilt agent\n",
    "\n",
    "### Modern ReAct Pattern Flow\n",
    "\n",
    "```\n",
    "User Input\n",
    "    ‚Üì\n",
    "LLM Reasoning (implicit)\n",
    "    ‚Üì\n",
    "Decision: Need tools?\n",
    "    ‚îú‚îÄ‚Üí YES: Call tool ‚Üí Get results ‚Üí Loop back\n",
    "    ‚îî‚îÄ‚Üí NO: Generate final answer ‚Üí End\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Install Dependencies\n",
    "\n",
    "Run this cell to install all required packages in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All dependencies installed!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install -q \\\n",
    "    langgraph\\\n",
    "    langchain-core\\\n",
    "    langchain-openai\\\n",
    "    langchain-valyu \\\n",
    "    python-dotenv \\\n",
    "    requests\n",
    "\n",
    "print(\"‚úÖ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup Environment\n",
    "\n",
    "**Recommended:**\n",
    "Set up Holistic AI Bedrock Proxy API credentials in `.env`:\n",
    "\n",
    "```bash\n",
    "HOLISTIC_AI_TEAM_ID=tutorials_api\n",
    "HOLISTIC_AI_API_TOKEN=your-token-here\n",
    "```\n",
    "\n",
    "[API Guide](../assets/api-guide.pdf)\n",
    "\n",
    "**Alternative:**\n",
    "If you prefer OpenAI:\n",
    "\n",
    "```bash\n",
    "OPENAI_API_KEY=your-openai-api-key-here\n",
    "```\n",
    "\n",
    "**Optional:**\n",
    "```bash\n",
    "VALYU_API_KEY=your-valyu-api-key-here\n",
    "```\n",
    "\n",
    "**Note:** The tutorial uses Holistic AI Bedrock by default (recommended). OpenAI is optional - to use it, call get_chat_model(model_name, use_openai=True) and set OPENAI_API_KEY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Loaded configuration from .env file\n",
      "\n",
      "üîë API Key Status:\n",
      "  ‚úÖ Holistic AI Bedrock credentials loaded (will use Bedrock)\n",
      "  ‚úÖ Valyu API key loaded: 2Qx4tyw7ey...\n",
      "\n",
      "üìÅ Working directory: /Users/zekunwu/Desktop/hackthon-2026/tutorials\n",
      "\n",
      "‚úÖ Holistic AI Bedrock helper function loaded\n",
      "\n",
      "‚úÖ All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ============================================\n",
    "# OPTION 1: Set API keys directly (Quick Start)\n",
    "# ============================================\n",
    "# Uncomment and set your keys here:\n",
    "# Recommended: Holistic AI Bedrock\n",
    "# os.environ[\"HOLISTIC_AI_TEAM_ID\"] = \"tutorials_api\"\n",
    "# os.environ[\"HOLISTIC_AI_API_TOKEN\"] = \"your-token-here\"\n",
    "# Alternative: OpenAI\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-openai-key-here\"\n",
    "# Optional: Valyu\n",
    "# os.environ[\"VALYU_API_KEY\"] = \"your-valyu-key-here\"\n",
    "\n",
    "# ============================================\n",
    "# OPTION 2: Load from .env file (Recommended)\n",
    "# ============================================\n",
    "# Try to load from .env file in parent directory\n",
    "env_path = Path('../.env')\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(\"üìÑ Loaded configuration from .env file\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No .env file found - using environment variables or hardcoded keys\")\n",
    "\n",
    "# ============================================\n",
    "# Verify API keys are set\n",
    "# ============================================\n",
    "print(\"\\nüîë API Key Status:\")\n",
    "if os.getenv('HOLISTIC_AI_TEAM_ID') and os.getenv('HOLISTIC_AI_API_TOKEN'):\n",
    "    print(\"  ‚úÖ Holistic AI Bedrock credentials loaded (will use Bedrock)\")\n",
    "elif os.getenv('OPENAI_API_KEY'):\n",
    "    print(\"  ‚ö†Ô∏è  OpenAI API key loaded (Bedrock credentials not set)\")\n",
    "    print(\"     üí° Tip: Set HOLISTIC_AI_TEAM_ID and HOLISTIC_AI_API_TOKEN to use Bedrock (recommended)\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è  No API keys found\")\n",
    "    print(\"     Set Holistic AI Bedrock credentials (recommended) or OpenAI key\")\n",
    "\n",
    "if os.getenv('VALYU_API_KEY'):\n",
    "    key_preview = os.getenv('VALYU_API_KEY')[:10] + \"...\"\n",
    "    print(f\"  ‚úÖ Valyu API key loaded: {key_preview}\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è  Valyu API key not found - search tool will not work\")\n",
    "\n",
    "print(\"\\nüìÅ Working directory:\", Path.cwd())\n",
    "\n",
    "# ============================================\n",
    "# Import Holistic AI Bedrock helper function\n",
    "# ============================================\n",
    "# Import from core module (recommended)\n",
    "import sys\n",
    "try:\n",
    "    sys.path.insert(0, '../core')\n",
    "    from react_agent.holistic_ai_bedrock import HolisticAIBedrockChat, get_chat_model\n",
    "    print(\"\\n‚úÖ Holistic AI Bedrock helper function loaded\")\n",
    "except ImportError:\n",
    "    print(\"\\n‚ö†Ô∏è  Could not import from core - will use OpenAI only\")\n",
    "    print(\"   Make sure core/react_agent/holistic_ai_bedrock.py exists\")\n",
    "\n",
    "# Import official packages\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "print(\"\\n‚úÖ All imports successful!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Helper Function\n",
    "\n",
    "This helper function uses by default the best available model:\n",
    "\n",
    "**Recommended:**\n",
    "- **Holistic AI Bedrock** - Uses Claude, Llama, Nova models via Bedrock Proxy\n",
    "- Set `HOLISTIC_AI_TEAM_ID` and `HOLISTIC_AI_API_TOKEN` in `.env`\n",
    "- [API Guide](../assets/api-guide.pdf)\n",
    "\n",
    "**Alternative:**\n",
    "- **OpenAI** - Uses OpenAI models (optional)\n",
    "\n",
    "You can use model names like:\n",
    "- `claude-3-5-sonnet` ‚Üí Uses Holistic AI Bedrock (Claude Sonnet) - **Recommended**\n",
    "- `claude-3-5-haiku` ‚Üí Uses Holistic AI Bedrock (Claude Haiku - faster)\n",
    "- `gpt-5-mini` ‚Üí Uses OpenAI (optional, requires use_openai=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Understanding the Difference\n",
    "\n",
    "### Direct LLM Call vs ReAct Agent\n",
    "\n",
    "| Aspect | Direct LLM Call | ReAct Agent |\n",
    "|--------|----------------|-------------|\n",
    "| **Pattern** | One-shot: question ‚Üí answer | Reasoning + Acting in a loop |\n",
    "| **Tools** | ‚ùå No tool access | ‚úÖ Can use search, APIs, databases |\n",
    "| **Multi-step** | ‚ùå Single response | ‚úÖ Can break down complex tasks |\n",
    "| **Self-correction** | ‚ùå Cannot retry | ‚úÖ Can reflect and improve |\n",
    "| **Use Case** | Simple Q&A, summarization | Research, planning, tool use |\n",
    "\n",
    "Let's see this in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EXAMPLE 1: Direct LLM Call\n",
      "======================================================================\n",
      "\n",
      "‚ùì Question: What is quantum computing?\n",
      "\n",
      "üí¨ Response: Quantum computing is a type of computing that uses quantum mechanics principles to perform calculations and process information. Unlike traditional computers that use bits (0s and 1s), quantum computers use quantum bits or \"qubits\" that can exist in multiple states simultaneously due to a phenomenon called superposition.\n",
      "\n",
      "Key features of quantum computing include:\n",
      "\n",
      "1. Superposition: Qubits can be in multiple states at once\n",
      "2. Entanglement: Qubits can be interconnected in ways that classical bits cannot\n",
      "3. Interference: Quantum states can be manipulated to enhance correct solutions\n",
      "\n",
      "Potential applications include:\n",
      "\n",
      "1. Complex problem-solving\n",
      "2. Cryptography and security\n",
      "3. Drug discovery and molecular modeling\n",
      "4. Financial modeling\n",
      "5. Climate change simulation\n",
      "6. Optimization problems\n",
      "\n",
      "While quantum computers are still in early development, they have the potential to solve certain problems exponentially faster than classical computers. However, they also face significant challenges in terms of maintaining qubit stability and reducing error rates.\n",
      "\n",
      "Major companies like IBM, Google, and Microsoft are actively developing quantum computers, though practical, large-scale quantum computers are still years away from widespread implementation.\n",
      "\n",
      "‚è±Ô∏è  Time: 5.66s\n",
      "\n",
      "‚úÖ Simple and fast!\n",
      "‚ùå But... can't use tools, can't reason through steps, single response only\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Example 1: Direct LLM Call (Simple)\n",
    "print(\"=\"*70)\n",
    "print(\"EXAMPLE 1: Direct LLM Call\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Use the helper function - uses Holistic AI Bedrock by default\n",
    "llm = get_chat_model(\"claude-3-5-sonnet\")  # Uses Holistic AI Bedrock (recommended)\n",
    "\n",
    "question = \"What is quantum computing?\"\n",
    "print(f\"\\n‚ùì Question: {question}\")\n",
    "\n",
    "start_time = time.time()\n",
    "response = llm.invoke(question)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\nüí¨ Response: {response.content}\")\n",
    "print(f\"\\n‚è±Ô∏è  Time: {elapsed:.2f}s\")\n",
    "print(\"\\n‚úÖ Simple and fast!\")\n",
    "print(\"‚ùå But... can't use tools, can't reason through steps, single response only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Comparison\n",
    "\n",
    "#### Direct LLM Call Flow\n",
    "```\n",
    "User Question ‚Üí LLM ‚Üí Response \n",
    "```\n",
    "- ‚ö° Fast and simple\n",
    "- ‚ùå Can't use tools, no multi-step reasoning\n",
    "\n",
    "#### ReAct Agent Flow  \n",
    "```\n",
    "User Question ‚Üí LLM (with tools bound)\n",
    "                    ‚Üì\n",
    "          Need to use a tool?\n",
    "                ‚Üô        ‚Üò\n",
    "              YES        NO\n",
    "               ‚Üì          ‚Üì\n",
    "        Execute Tool   Final Answer\n",
    "               ‚Üì\n",
    "        Get Results\n",
    "               ‚Üì\n",
    "        Loop back to LLM ‚Üê‚îò\n",
    "```\n",
    "- ‚úÖ Can use tools (search, APIs, databases)\n",
    "- ‚úÖ Multi-step reasoning and self-correction\n",
    "- ‚úÖ Full observability of the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Your First ReAct Agent\n",
    "\n",
    "Now let's use **LangGraph's prebuilt `create_react_agent`** function. This is the official implementation that handles:\n",
    "- State management (message history)\n",
    "- Tool binding (native function calling)\n",
    "- Execution loop (reasoning ‚Üí acting ‚Üí observing)\n",
    "- Error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EXAMPLE 2: ReAct Agent (No Tools)\n",
      "======================================================================\n",
      "\n",
      "‚ùì Same Question: What is quantum computing?\n",
      "\n",
      "üí¨ Response: Quantum computing is a type of computing that uses quantum mechanics principles to process information. Unlike traditional computers that use bits (0s and 1s), quantum computers use quantum bits or \"qubits\" that can exist in multiple states simultaneously due to a phenomenon called superposition.\n",
      "\n",
      "Key aspects of quantum computing include:\n",
      "\n",
      "1. Superposition: Qubits can represent multiple states at once, allowing for parallel processing\n",
      "\n",
      "2. Entanglement: Qubits can be linked together in ways that classical bits cannot, enabling complex calculations\n",
      "\n",
      "3. Speed: Quantum computers can solve certain problems exponentially faster than classical computers\n",
      "\n",
      "4. Applications: Potential uses include:\n",
      "- Cryptography\n",
      "- Drug discovery\n",
      "- Climate modeling\n",
      "- Financial modeling\n",
      "- Optimization problems\n",
      "\n",
      "Current challenges:\n",
      "\n",
      "1. Maintaining qubit stability\n",
      "2. Error correction\n",
      "3. Scaling up systems\n",
      "4. Cost and complexity\n",
      "\n",
      "While quantum computers are still in early stages of development, they have the potential to revolutionize computing for specific applications, though they're not expected to replace classical computers for everyday tasks.\n",
      "\n",
      "Many major tech companies (IBM, Google, Microsoft) and governments are investing heavily in quantum computing research and development.\n",
      "\n",
      "‚è±Ô∏è  Time: 6.52s\n",
      "üìä Messages in conversation: 2\n",
      "\n",
      "‚úÖ Agent can maintain context, use tools (when provided), and handle multi-turn!\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Example 2: ReAct Agent (no tools yet)\n",
    "print(\"=\"*70)\n",
    "print(\"EXAMPLE 2: ReAct Agent (No Tools)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create LLM using helper function\n",
    "llm = get_chat_model(\"claude-3-5-sonnet\")\n",
    "\n",
    "# Create ReAct agent with NO tools (for now)\n",
    "agent = create_react_agent(llm, tools=[])\n",
    "\n",
    "# Use the same question from Example 1\n",
    "question = \"What is quantum computing?\"\n",
    "print(f\"\\n‚ùì Same Question: {question}\")\n",
    "\n",
    "start_time = time.time()\n",
    "result = agent.invoke({\"messages\": [HumanMessage(content=question)]})\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\nüí¨ Response: {result['messages'][-1].content}\")\n",
    "print(f\"\\n‚è±Ô∏è  Time: {elapsed:.2f}s\")\n",
    "print(f\"üìä Messages in conversation: {len(result['messages'])}\")\n",
    "print(\"\\n‚úÖ Agent can maintain context, use tools (when provided), and handle multi-turn!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Just Happened?\n",
    "\n",
    "The agent:\n",
    "1. Received your question as a `HumanMessage`\n",
    "2. LLM processed it (no tools needed for this simple question)\n",
    "3. Generated an `AIMessage` with the answer\n",
    "4. Returned the full conversation state\n",
    "\n",
    "**Key difference from direct LLM call**: The agent maintains state and can loop through tool calls if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Understanding Valyu Search Tool\n",
    "\n",
    "Before adding tools to the agent, let's understand what the Valyu search tool does:\n",
    "\n",
    "**Valyu** is an AI-powered search engine that:\n",
    "- Searches across proprietary sources + web\n",
    "- Returns structured results with title, URL, content, relevance scores\n",
    "- Optimized for AI agents (not just humans)\n",
    "\n",
    "Let's test it directly first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Official Valyu Integration\n",
    "\n",
    "We'll use the official `langchain-valyu` package which provides:\n",
    "- **ValyuSearchTool**: Search tool compatible with LangChain agents\n",
    "- **ValyuRetriever**: For RAG (Retrieval-Augmented Generation) pipelines\n",
    "\n",
    "Documentation: https://python.langchain.com/docs/integrations/providers/valyu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Testing Valyu Search Tool Directly\n",
      "======================================================================\n",
      "Query: latest developments in quantum computing\n",
      "\n",
      "üìÑ Search Results (first 500 chars):\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"error\": \"\",\n",
      "  \"tx_id\": \"tx_8924ad79-e661-41b3-af15-a0797cfb0016\",\n",
      "  \"query\": \"latest developments in quantum computing\",\n",
      "  \"results\": [\n",
      "    {\n",
      "      \"title\": \"News - Quantum Computing Report\",\n",
      "      \"url\": \"https://quantumcomputingreport.com/news/?utm_source=valyu.ai&utm_medium=referral\",\n",
      "      \"content\": \"# News\\n\\nRecent news items published within the last 6 months on quantum computing developments are listed below. Click on the hyperlinked item to go to the press relea...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üìä Total data returned: 94641 characters\n",
      "‚úÖ This data will be passed to the agent to answer questions!\n"
     ]
    }
   ],
   "source": [
    "# Import official Valyu tool from langchain-valyu package\n",
    "from langchain_valyu import ValyuSearchTool\n",
    "\n",
    "# Create search tool with configuration\n",
    "search_tool = ValyuSearchTool(\n",
    "    valyu_api_key=os.getenv(\"VALYU_API_KEY\"),\n",
    "    # Optional: configure search parameters (can also be set per-call)\n",
    "    # search_type=\"all\",  # Search both proprietary and web sources\n",
    "    # max_num_results=5,   # Limit results\n",
    "    # relevance_threshold=0.5,  # Minimum relevance score\n",
    "    # max_price=20.0  # Maximum cost in dollars\n",
    ")\n",
    "\n",
    "# Test it directly\n",
    "print(\"üîç Testing Valyu Search Tool Directly\")\n",
    "print(\"=\"*70)\n",
    "test_query = \"latest developments in quantum computing\"\n",
    "print(f\"Query: {test_query}\\n\")\n",
    "\n",
    "# Call the search tool\n",
    "search_results = search_tool._run(\n",
    "    query=test_query,\n",
    "    search_type=\"all\",\n",
    "    max_num_results=5\n",
    ")\n",
    "\n",
    "# Display results (truncated for readability)\n",
    "result_str = str(search_results)\n",
    "print(\"üìÑ Search Results (first 500 chars):\")\n",
    "print(\"-\"*70)\n",
    "print(result_str[:500] + \"...\" if len(result_str) > 500 else result_str)\n",
    "print(\"-\"*70)\n",
    "print(f\"\\nüìä Total data returned: {len(result_str)} characters\")\n",
    "print(\"‚úÖ This data will be passed to the agent to answer questions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: The Power of Tools - WITH vs WITHOUT Search\n",
    "\n",
    "Now let's see the real magic! We'll ask the same question to:\n",
    "1. **Agent WITHOUT search** - Will give generic/outdated answer\n",
    "2. **Agent WITH search** - Will use real-time web data\n",
    "\n",
    "This demonstrates why tools are critical for ReAct agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEST 1: Agent WITHOUT Search\n",
      "======================================================================\n",
      "‚ùì Question: What are the latest breakthroughs in quantum computing in 2025?\n",
      "\n",
      "üí¨ Response (NO search):\n",
      "----------------------------------------------------------------------\n",
      "I need to point out that I cannot provide information about quantum computing breakthroughs in 2025, as I have a knowledge cutoff date and cannot access real-time or future information. I aim to be transparent about what I do and don't know. I'd be happy to discuss known quantum computing developments up to my last update, or we could focus on the general trajectory of the field based on verified ...\n",
      "----------------------------------------------------------------------\n",
      "‚è±Ô∏è  Time: 3.05s\n",
      "\n",
      "‚ö†Ô∏è  Note: Generic answer, likely outdated or vague (LLM training data cutoff)\n"
     ]
    }
   ],
   "source": [
    "# Test question about recent events (requires current information)\n",
    "recent_question = \"What are the latest breakthroughs in quantum computing in 2025?\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST 1: Agent WITHOUT Search\")\n",
    "print(\"=\"*70)\n",
    "print(f\"‚ùì Question: {recent_question}\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "result_no_search = agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=recent_question)]\n",
    "})\n",
    "elapsed_no_search = time.time() - start_time\n",
    "\n",
    "print(\"üí¨ Response (NO search):\")\n",
    "print(\"-\"*70)\n",
    "response_text = result_no_search['messages'][-1].content\n",
    "print(response_text[:400] + \"...\" if len(response_text) > 400 else response_text)\n",
    "print(\"-\"*70)\n",
    "print(f\"‚è±Ô∏è  Time: {elapsed_no_search:.2f}s\")\n",
    "print(f\"\\n‚ö†Ô∏è  Note: Generic answer, likely outdated or vague (LLM training data cutoff)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TEST 2: Agent WITH Search\n",
      "======================================================================\n",
      "\n",
      "‚ùì Same Question: What are the latest breakthroughs in quantum computing in 2025?\n",
      "\n",
      "üí¨ Response (WITH search):\n",
      "----------------------------------------------------------------------\n",
      "Based on the search results, here are the key quantum computing breakthroughs and developments in 2025:\n",
      "\n",
      "1. Microsoft's Majorana 1 Processor:\n",
      "- Introduced in February 2025\n",
      "- Designed to scale to a million qubits using topological qubits\n",
      "- Uses hardware-protected qubits and a novel topological architecture\n",
      "- Aims to provide a clear path toward scalable quantum computing\n",
      "\n",
      "2. Google's Willow Chip:\n",
      "- Demonstrated quantum supremacy for specific computational tasks\n",
      "- Achieved exponential reduction in errors as more qubits are added\n",
      "- Performed computations in minutes that would take classical superc...\n",
      "----------------------------------------------------------------------\n",
      "‚è±Ô∏è  Time: 27.74s\n",
      "\n",
      "‚úÖ Note: Real-time data, specific sources, up-to-date information!\n"
     ]
    }
   ],
   "source": [
    "# Now create agent WITH search tool\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST 2: Agent WITH Search\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create new agent with Valyu search tool (uses Holistic AI Bedrock by default)\n",
    "llm_with_tools = get_chat_model(\"claude-3-5-sonnet\")\n",
    "agent_with_search = create_react_agent(\n",
    "    llm_with_tools,\n",
    "    tools=[search_tool]  # Add the search tool!\n",
    ")\n",
    "\n",
    "print(f\"\\n‚ùì Same Question: {recent_question}\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "result_with_search = agent_with_search.invoke({\n",
    "    \"messages\": [HumanMessage(content=recent_question)]\n",
    "})\n",
    "elapsed_with_search = time.time() - start_time\n",
    "\n",
    "print(\"üí¨ Response (WITH search):\")\n",
    "print(\"-\"*70)\n",
    "response_text = result_with_search['messages'][-1].content\n",
    "print(response_text[:600] + \"...\" if len(response_text) > 600 else response_text)\n",
    "print(\"-\"*70)\n",
    "print(f\"‚è±Ô∏è  Time: {elapsed_with_search:.2f}s\")\n",
    "print(f\"\\n‚úÖ Note: Real-time data, specific sources, up-to-date information!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Happened Under the Hood?\n",
    "\n",
    "When you gave the agent search capabilities:\n",
    "\n",
    "1. **LLM received the question** and analyzed it\n",
    "2. **Decided it needed current info** (can't answer from training data)\n",
    "3. **Called the Valyu search tool** with structured arguments\n",
    "4. **Received search results** with current 2025 information\n",
    "5. **Synthesized the answer** using the retrieved data\n",
    "\n",
    "This is the **ReAct pattern** in action:\n",
    "- **Re**ason: \"I need current information\"\n",
    "- **Act**: Call search tool\n",
    "- **Observe**: Get results\n",
    "- **Respond**: Synthesize answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Inspect the Message Trace\n",
    "\n",
    "Let's look at the conversation history to see the ReAct loop in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Message Trace (WITH search):\n",
      "======================================================================\n",
      "\n",
      "1. HumanMessage\n",
      "----------------------------------------------------------------------\n",
      "   User: What are the latest breakthroughs in quantum computing in 2025?...\n",
      "\n",
      "2. AIMessage\n",
      "----------------------------------------------------------------------\n",
      "   AI decided to call tool: valyu_deep_search\n",
      "   Args: {'query': 'major breakthroughs developments quantum computing 2025', 'start_date': '2025-01-01', 'end_date': '2025-12-31', 'max_num_results': 10}\n",
      "\n",
      "3. ToolMessage\n",
      "----------------------------------------------------------------------\n",
      "   Tool returned: {\n",
      "  \"success\": true,\n",
      "  \"error\": \"\",\n",
      "  \"tx_id\": \"tx_62ff553e-5d04-4f1e-9740-a723225f1247\",\n",
      "  \"query\":...\n",
      "\n",
      "4. AIMessage\n",
      "----------------------------------------------------------------------\n",
      "   AI response: Based on the search results, here are the key quantum computing breakthroughs and developments in 2025:\n",
      "\n",
      "1. Microsoft's Majorana 1 Processor:\n",
      "- Introd...\n",
      "\n",
      "======================================================================\n",
      "Total messages: 4\n",
      "\n",
      "This shows the complete ReAct loop: User ‚Üí AI (tool call) ‚Üí Tool ‚Üí AI (answer)\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Message Trace (WITH search):\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, msg in enumerate(result_with_search['messages']):\n",
    "    msg_type = type(msg).__name__\n",
    "    print(f\"\\n{i+1}. {msg_type}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    if msg_type == \"HumanMessage\":\n",
    "        print(f\"   User: {msg.content[:100]}...\")\n",
    "    \n",
    "    elif msg_type == \"AIMessage\":\n",
    "        if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "            print(f\"   AI decided to call tool: {msg.tool_calls[0]['name']}\")\n",
    "            print(f\"   Args: {msg.tool_calls[0]['args']}\")\n",
    "        else:\n",
    "            content_preview = msg.content[:150] + \"...\" if len(msg.content) > 150 else msg.content\n",
    "            print(f\"   AI response: {content_preview}\")\n",
    "    \n",
    "    elif msg_type == \"ToolMessage\":\n",
    "        content_preview = msg.content[:100] + \"...\" if len(msg.content) > 100 else msg.content\n",
    "        print(f\"   Tool returned: {content_preview}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"Total messages: {len(result_with_search['messages'])}\")\n",
    "print(\"\\nThis shows the complete ReAct loop: User ‚Üí AI (tool call) ‚Üí Tool ‚Üí AI (answer)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Try Multi-Turn Conversation\n",
    "\n",
    "ReAct agents maintain state, so you can have multi-turn conversations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ Multi-Turn Conversation Example\n",
      "======================================================================\n",
      "\n",
      "üë§ Turn 1: Search for the latest AI agent frameworks in 2025\n",
      "ü§ñ Agent: Based on the search results, here are the key AI agent frameworks that are leading the field in 2025:\n",
      "\n",
      "1. LangChain\n",
      "- Most widely adopted framework with over 110k GitHub stars\n",
      "- Provides modular desig...\n",
      "\n",
      "üë§ Turn 2: Which one is best for production use?\n",
      "ü§ñ Agent: Based on the search results, for production use in 2025, Microsoft Agent Framework and LangChain emerge as the most production-ready options, with different strengths:\n",
      "\n",
      "Microsoft Agent Framework is be...\n",
      "\n",
      "======================================================================\n",
      "‚úÖ The agent remembers context from previous turns!\n",
      "Total messages in conversation: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"üí¨ Multi-Turn Conversation Example\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Start a new conversation\n",
    "conversation = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"Search for the latest AI agent frameworks in 2025\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Turn 1\n",
    "print(\"\\nüë§ Turn 1: Search for the latest AI agent frameworks in 2025\")\n",
    "result1 = agent_with_search.invoke(conversation)\n",
    "print(f\"ü§ñ Agent: {result1['messages'][-1].content[:200]}...\\n\")\n",
    "\n",
    "# Turn 2 - follow up question (agent has context from turn 1)\n",
    "result1['messages'].append(\n",
    "    HumanMessage(content=\"Which one is best for production use?\")\n",
    ")\n",
    "print(\"üë§ Turn 2: Which one is best for production use?\")\n",
    "result2 = agent_with_search.invoke(result1)\n",
    "print(f\"ü§ñ Agent: {result2['messages'][-1].content[:200]}...\\n\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"‚úÖ The agent remembers context from previous turns!\")\n",
    "print(f\"Total messages in conversation: {len(result2['messages'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You've learned:\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Direct LLM vs ReAct Agents**\n",
    "   - Direct LLM: Fast, simple, single-step\n",
    "   - ReAct Agent: Multi-step reasoning, tool use, self-correction\n",
    "\n",
    "2. **Modern ReAct Pattern**\n",
    "   - Uses function calling (not text parsing like original 2022 paper)\n",
    "   - Structured tool execution via LLM APIs\n",
    "   - Message-based state management\n",
    "\n",
    "3. **LangGraph's `create_react_agent`**\n",
    "   - Official prebuilt implementation\n",
    "   - Handles state, tools, execution loop\n",
    "   - Production-ready pattern\n",
    "\n",
    "4. **The Power of Tools**\n",
    "   - Agents without tools: Limited to training data\n",
    "   - Agents with tools: Access to real-time information\n",
    "   - Valyu search: AI-optimized search engine\n",
    "\n",
    "### When to Use ReAct Agents\n",
    "\n",
    "‚úÖ **Use ReAct agents when you need:**\n",
    "- Real-time information (web search, APIs)\n",
    "- Multi-step reasoning (planning, breaking down tasks)\n",
    "- Tool execution (databases, calculators, APIs)\n",
    "- Self-correction and iteration\n",
    "\n",
    "‚ùå **Use direct LLM calls when:**\n",
    "- Simple Q&A (no external data needed)\n",
    "- Text generation, summarization\n",
    "- Speed is critical\n",
    "- Task is single-step\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Continue your learning:\n",
    "\n",
    "1. **02_custom_tools.ipynb** - Build your own custom tools\n",
    "2. **03_structured_output.ipynb** - Get JSON responses with Pydantic schemas\n",
    "3. **04_model_monitoring.ipynb** - Track costs, tokens, and carbon footprint\n",
    "\n",
    "---\n",
    "\n",
    "### Resources\n",
    "\n",
    "- LangGraph Docs: https://langchain-ai.github.io/langgraph/\n",
    "- ReAct Paper (2022): https://arxiv.org/abs/2210.03629\n",
    "- Valyu API: https://valyu.ai\n",
    "\n",
    "---\n",
    "\n",
    "**Pro Tip**: Always start with the simplest approach (direct LLM) and add complexity (agents, tools) only when needed. The best code is the simplest code that works!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
